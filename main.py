import os
import ccxt.async_support as ccxt
import pandas as pd
import pandas_ta_classic as ta
import json
import psycopg2
from psycopg2.extras import execute_values
import asyncio
from tqdm.asyncio import tqdm
from hurst import compute_Hc
from scipy.stats import skew
import numpy as np
import logging
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
from ccxt.base.errors import RateLimitExceeded, NetworkError, ExchangeError, ExchangeNotAvailable
import uvicorn
from fastapi import FastAPI, Request, HTTPException, BackgroundTasks
from contextlib import asynccontextmanager

# --- –ß–ê–°–¢–¨ 1: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤–µ–±-—Å–µ—Ä–≤–µ—Ä–∞ FastAPI ---

@asynccontextmanager
async def lifespan(app: FastAPI):
    """–£–ø—Ä–∞–≤–ª—è–µ—Ç –∂–∏–∑–Ω–µ–Ω–Ω—ã–º —Ü–∏–∫–ª–æ–º —Å–µ—Ä–≤–µ—Ä–∞: –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ."""
    logging.info("–°–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω –∏ –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ.")
    yield
    logging.info("–°–µ—Ä–≤–µ—Ä –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è.")

app = FastAPI(lifespan=lifespan)
SECRET_TOKEN = os.getenv("SECRET_TOKEN")

# --- –ß–ê–°–¢–¨ 2: –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –°–ö–†–ò–ü–¢–ê ---

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

EXCHANGES_TO_PROCESS = ['binance', 'bybit'] 
MIN_DAILY_VOLUME_USDT = 3_000_000
VOLUME_CATEGORIES = 6
BLACKLIST_FILE = 'blacklist.json'
ANALYSIS_PERIOD_DAYS = 90
MIN_HISTORY_DAYS = 180
HURST_TIMEFRAMES = ['4h', '8h', '12h', '1d']
ATR_PERIOD = 14
BTC_SYMBOL = 'BTC/USDT'
CONCURRENT_REQUEST_LIMIT = 10
RETRY_ATTEMPTS = 3
RETRY_WAIT_MIN = 1
RETRY_WAIT_MAX = 10

# --- –ß–ê–°–¢–¨ 3: –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –ò –°–õ–£–ñ–ï–ë–ù–´–ï –§–£–ù–ö–¶–ò–ò ---

def load_blacklist():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —á–µ—Ä–Ω—ã–π —Å–ø–∏—Å–æ–∫ –º–æ–Ω–µ—Ç –∏–∑ —Ñ–∞–π–ª–∞ blacklist.json."""
    try:
        with open(BLACKLIST_FILE, 'r') as f:
            logging.info("–ß–µ—Ä–Ω—ã–π —Å–ø–∏—Å–æ–∫ blacklist.json —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω.")
            return json.load(f)
    except FileNotFoundError:
        logging.warning(f"–§–∞–π–ª {BLACKLIST_FILE} –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—É—Å—Ç–æ–π —á–µ—Ä–Ω—ã–π —Å–ø–∏—Å–æ–∫.")
        return []
    except json.JSONDecodeError:
        logging.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {BLACKLIST_FILE}. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—É—Å—Ç–æ–π —á–µ—Ä–Ω—ã–π —Å–ø–∏—Å–æ–∫.")
        return []

RETRYABLE_EXCEPTIONS = (RateLimitExceeded, NetworkError, ExchangeError, ExchangeNotAvailable)

@retry(
    stop=stop_after_attempt(RETRY_ATTEMPTS),
    wait=wait_exponential(multiplier=1, min=RETRY_WAIT_MIN, max=RETRY_WAIT_MAX),
    retry=retry_if_exception_type(RETRYABLE_EXCEPTIONS),
    before_sleep=lambda retry_state: logging.warning(f"Retrying API call... Attempt #{retry_state.attempt_number}")
)
async def fetch_with_retry(func, *args, **kwargs):
    """–ù–∞–¥–µ–∂–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã—Ö –≤—ã–∑–æ–≤–æ–≤ API —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏."""
    return await func(*args, **kwargs)

def calculate_entropy(series, bins=10):
    """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —ç–Ω—Ç—Ä–æ–ø–∏—é –®–µ–Ω–Ω–æ–Ω–∞ –¥–ª—è —Å–µ—Ä–∏–∏ –¥–∞–Ω–Ω—ã—Ö, —É—Å—Ç–æ–π—á–∏–≤–æ –∫ NaN/inf."""
    # (üö© 7) –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ —Ä–∞—Å—á–µ—Ç–æ–º
    cleaned_series = series.replace([np.inf, -np.inf], np.nan).dropna()
    if cleaned_series.empty or cleaned_series.nunique() <= 1:
        return 0.0
    try:
        hist = np.histogram(cleaned_series, bins=bins, density=False)[0]
        probabilities = hist / len(cleaned_series)
        probabilities = probabilities[probabilities > 0]
        return -np.sum(probabilities * np.log2(probabilities))
    except Exception:
        return None

async def initialize_exchange(exchange_name):
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –±–∏—Ä–∂—É –∏ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ BTC_SYMBOL."""
    logging.info(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∏—Ä–∂–∏ {exchange_name}...")
    try:
        exchange_map = {'binance': ccxt.binance, 'bybit': ccxt.bybit}
        exchange_class = exchange_map.get(exchange_name)
        if not exchange_class:
            logging.error(f"–ë–∏—Ä–∂–∞ '{exchange_name}' –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è.")
            return None
        
        exchange = exchange_class({'options': {'defaultType': 'swap'}, 'timeout': 30000})
        await exchange.load_markets()

        # (üö© 4, 9) –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞–ª–∏—á–∏—è BTC_SYMBOL
        if BTC_SYMBOL not in exchange.markets:
            logging.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {BTC_SYMBOL} –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∞ –±–∏—Ä–∂–µ {exchange_name}. –≠—Ç–∞ –±–∏—Ä–∂–∞ –Ω–µ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è.")
            await exchange.close()
            return None

        return exchange
    except Exception as e:
        logging.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –±–∏—Ä–∂—É {exchange_name}: {e}")
        return None

# --- –ß–ê–°–¢–¨ 4: –ì–õ–ê–í–ù–ê–Ø –õ–û–ì–ò–ö–ê –ê–ù–ê–õ–ò–ó–ê ---

async def run_analysis_logic():
    """–°–æ–¥–µ—Ä–∂–∏—Ç –≤—Å—é –æ—Å–Ω–æ–≤–Ω—É—é –ª–æ–≥–∏–∫—É –∞–Ω–∞–ª–∏–∑–∞."""
    logging.info("–ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ —Ç—Ä–∏–≥–≥–µ—Ä—É...")
    
    blacklist = load_blacklist()
    init_tasks = [initialize_exchange(name) for name in EXCHANGES_TO_PROCESS]
    initialized_exchanges = await asyncio.gather(*init_tasks)
    exchanges_map = {ex.id: ex for ex in initialized_exchanges if ex}

    # (üö© 12) –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∑–∞–∫—Ä—ã—Ç–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤
    try:
        if not exchanges_map:
            logging.critical("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–π –±–∏—Ä–∂–∏. –í—ã—Ö–æ–¥.")
            return

        async def fetch_markets(exchange):
            logging.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ —Ä—ã–Ω–∫–æ–≤ —Å –±–∏—Ä–∂–∏ {exchange.id}...")
            try:
                tickers = await fetch_with_retry(exchange.fetch_tickers)
                return tickers
            except Exception as e:
                logging.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ä—ã–Ω–∫–∏/—Ç–∏–∫–µ—Ä—ã —Å {exchange.id}: {e}")
                return {}

        fetch_tasks = [fetch_markets(ex) for ex in exchanges_map.values()]
        all_tickers_list = await asyncio.gather(*fetch_tasks)
        all_tickers = {ex.id: tickers for ex, tickers in zip(exchanges_map.values(), all_tickers_list)}

        def filter_coins(exchange, tickers):
            filtered = {}
            for symbol, ticker in tickers.items():
                market_data = exchange.markets.get(symbol)
                if not (market_data and market_data.get('swap', False) and market_data.get('quote', '').upper() == 'USDT'):
                    continue
                if not (ticker.get('quoteVolume') and ticker['quoteVolume'] >= MIN_DAILY_VOLUME_USDT):
                    if symbol != BTC_SYMBOL: continue
                base_currency = market_data.get('base', '').upper()
                if base_currency in blacklist: continue
                filtered[symbol] = {'quote_volume_24h': ticker['quoteVolume'], 'base_currency': base_currency}
            logging.info(f"–ù–∞ –±–∏—Ä–∂–µ {exchange.id} –Ω–∞–π–¥–µ–Ω–æ {len(filtered)} –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –º–æ–Ω–µ—Ç.")
            return filtered

        all_exchanges_coins = {ex.id: filter_coins(ex, all_tickers[ex.id]) for ex in exchanges_map.values()}
        
        # (üö© 2) –û—Å—Ç–∞–≤–ª–µ–Ω–æ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π –ø–æ –≤–∞—à–µ–º—É —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—é: –∞–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
        def aggregate_exchanges_data(all_exchanges_coins):
            logging.info("–ê–≥—Ä–µ–≥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö —Å–æ –≤—Å–µ—Ö –±–∏—Ä–∂ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É...")
            processed_coins = {}
            priority_order = [ex_id for ex_id in EXCHANGES_TO_PROCESS if ex_id in exchanges_map]
            
            for ex_id in priority_order:
                for symbol, data in all_exchanges_coins[ex_id].items():
                    if symbol not in processed_coins:
                        processed_coins[symbol] = {**data, 'exchanges': [ex_id]}
                    else:
                        processed_coins[symbol]['exchanges'].append(ex_id)
            logging.info(f"–í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –º–æ–Ω–µ—Ç –ø–æ—Å–ª–µ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏: {len(processed_coins)}")
            return [{'symbol': symbol, **data} for symbol, data in processed_coins.items()]

        def categorize_by_volume(df, num_categories):
            if df.empty or 'quote_volume_24h' not in df.columns or df['quote_volume_24h'].isnull().all():
                df['category'] = None
                return df
            logging.info(f"–ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è –º–æ–Ω–µ—Ç –Ω–∞ {num_categories} –≥—Ä—É–ø–ø...")
            # (üö© 11) –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ qcut
            df['category'] = pd.qcut(df['quote_volume_24h'], q=num_categories, labels=range(1, num_categories + 1), duplicates='drop')
            return df
            
        async def analyze_single_coin(coin_data, exchanges_map, btc_data_cache, semaphore):
            symbol = coin_data['symbol']
            
            # (üö© 3) –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: Fallback-–ª–æ–≥–∏–∫–∞ –¥–ª—è –±–∏—Ä–∂
            ohlcv_data = {}
            for exchange_id in coin_data['exchanges']:
                exchange = exchanges_map[exchange_id]
                async with semaphore:
                    try:
                        # (üö© 1) –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏
                        limit_for_history_check = MIN_HISTORY_DAYS + ATR_PERIOD
                        ohlcv_1d = await fetch_with_retry(exchange.fetch_ohlcv, symbol, '1d', limit=limit_for_history_check)

                        # (üö© 1) –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –ù–∞–¥–µ–∂–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å–≤–µ—á–µ–π
                        if len(ohlcv_1d) < MIN_HISTORY_DAYS:
                            logging.info(f"–ü—Ä–æ–ø—É—Å–∫ {symbol}: –∏—Å—Ç–æ—Ä–∏—è —Ç–æ—Ä–≥–æ–≤ ({len(ohlcv_1d)} –¥–Ω–µ–π) –º–µ–Ω—å—à–µ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ —Ç—Ä–µ–±—É–µ–º–æ–π ({MIN_HISTORY_DAYS} –¥–Ω–µ–π).")
                            return None # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –º–æ–Ω–µ—Ç—É
                        
                        ohlcv_data['1d_data'] = ohlcv_1d
                        
                        tasks = {}
                        for tf in HURST_TIMEFRAMES:
                            limit = int((MIN_HISTORY_DAYS / (exchange.parse_timeframe(tf) / exchange.parse_timeframe('1d'))))
                            tasks[f'hurst_{tf}_data'] = fetch_with_retry(exchange.fetch_ohlcv, symbol, tf, limit=limit)
                        
                        hurst_responses = await asyncio.gather(*tasks.values(), return_exceptions=True)
                        for i, tf in enumerate(HURST_TIMEFRAMES):
                            ohlcv_data[f'hurst_{tf}_data'] = hurst_responses[i]

                        break # –£—Å–ø–µ—à–Ω–æ, –≤—ã—Ö–æ–¥–∏–º –∏–∑ —Ü–∏–∫–ª–∞
                    except Exception as e:
                        logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è {symbol} —Å –±–∏—Ä–∂–∏ {exchange_id}: {e}. –ü—Ä–æ–±—É—é —Å–ª–µ–¥—É—é—â—É—é...")
            
            if '1d_data' not in ohlcv_data:
                logging.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è {symbol} –Ω–∏ —Å –æ–¥–Ω–æ–π –∏–∑ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –±–∏—Ä–∂.")
                return None

            result_row = {'symbol': symbol}
            df_ohlcv_1d = pd.DataFrame(ohlcv_data['1d_data'], columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
            df_analysis = df_ohlcv_1d.tail(ANALYSIS_PERIOD_DAYS).copy()
            daily_returns = df_analysis['close'].pct_change().dropna()
            
            # ... (–≤—Å–µ —Ä–∞—Å—á–µ—Ç—ã –º–µ—Ç—Ä–∏–∫ –∫–∞–∫ –∏ —Ä–∞–Ω—å—à–µ)
            last_close = df_ohlcv_1d['close'].iloc[-1]
            if last_close > 0:
                atr_series = df_ohlcv_1d.ta.atr(length=ATR_PERIOD)
                if atr_series is not None and not atr_series.empty:
                    df_ohlcv_1d[f'ATR_{ATR_PERIOD}'] = atr_series
                    last_atr = df_ohlcv_1d[f'ATR_{ATR_PERIOD}'].iloc[-1]
                    result_row['volatility_index'] = round((last_atr / last_close) * 100, 4) if pd.notna(last_atr) else None
            
            # ...
            # (üö© 6, 10) –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–æ–∫ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ –•—ë—Ä—Å—Ç–∞
            for tf in HURST_TIMEFRAMES:
                hurst_data = ohlcv_data.get(f'hurst_{tf}_data')
                if isinstance(hurst_data, Exception):
                    logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –•—ë—Ä—Å—Ç–∞ ({tf}) –¥–ª—è {symbol}: {hurst_data}")
                    continue
                
                if hurst_data and len(hurst_data) > 100:
                    close_prices = [candle[4] for candle in hurst_data]
                    try:
                        if np.std(close_prices) > 0:
                            H, _, _ = compute_Hc(close_prices, kind='price', simplified=True)
                            result_row[f'hurst_{tf}'] = round(H, 4)
                    except Exception as e:
                        logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –•—ë—Ä—Å—Ç–∞ –¥–ª—è {symbol} –Ω–∞ {tf}: {e}")

            return result_row

        async def analyze_and_enhance_data(df, exchanges_map):
            if df.empty: return df
            logging.info(f"–ù–∞—á–∞–ª–æ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è {len(df)} –º–æ–Ω–µ—Ç...")
            btc_data_cache = {}
            semaphore = asyncio.Semaphore(CONCURRENT_REQUEST_LIMIT)
            
            analysis_tasks = []
            for _, row in df.iterrows():
                analysis_tasks.append(analyze_single_coin(row, exchanges_map, btc_data_cache, semaphore))

            analysis_results = []
            for f in tqdm.as_completed(analysis_tasks, desc="–ê–Ω–∞–ª–∏–∑ –º–æ–Ω–µ—Ç"):
                try:
                    result = await f
                    if result:
                        analysis_results.append(result)
                except Exception as e:
                    logging.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –∑–∞–¥–∞—á–µ –∞–Ω–∞–ª–∏–∑–∞: {e}")

            if not analysis_results:
                logging.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–π –º–æ–Ω–µ—Ç—ã.")
                return pd.DataFrame()

            df_results = pd.DataFrame(analysis_results).set_index('symbol')
            df = df.set_index('symbol').join(df_results).reset_index()
            return df

        def save_to_database(data_df):
            db_url = os.getenv('DATABASE_URL')
            if not db_url:
                logging.error("DATABASE_URL –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞.")
                return
            
            logging.info("–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ PostgreSQL...")
            conn = None
            final_columns = [
                'symbol', 'exchanges', 'category', 'logoUrl', 'volatility_index',
                'hurst_4h', 'hurst_8h', 'hurst_12h', 'hurst_1d',
                'efficiency_index', 'trend_harmony_index', 'btc_correlation',
                'returns_skewness', 'avg_wick_ratio', 'relative_strength_vs_btc', 
                'max_drawdown_percent', 'entropy', 'kurtosis', 'autocorrelation'
            ]
            
            # (üö© 5) –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π UPSERT –≤–º–µ—Å—Ç–æ TRUNCATE
            try:
                conn = psycopg2.connect(db_url)
                cursor = conn.cursor()
                
                update_cols = [f'"{col}" = EXCLUDED."{col}"' for col in final_columns if col != 'symbol']
                upsert_query = f"""
                INSERT INTO monthly_coin_selection ({', '.join(f'"{c}"' for c in final_columns)})
                VALUES %s
                ON CONFLICT (symbol) DO UPDATE SET
                {', '.join(update_cols)};
                """
                
                data_to_insert = [tuple(row) for row in data_df.reindex(columns=final_columns).where(pd.notna(data_df), None).to_numpy()]
                if data_to_insert:
                    execute_values(cursor, upsert_query, data_to_insert)
                    conn.commit()
                    logging.info(f"–£—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ/–æ–±–Ω–æ–≤–ª–µ–Ω–æ {len(data_to_insert)} –∑–∞–ø–∏—Å–µ–π.")
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö: {e}")
            finally:
                if conn: conn.close()
        
        aggregated_list = aggregate_exchanges_data(all_exchanges_coins)
        if not aggregated_list:
            logging.info("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –º–æ–Ω–µ—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ.")
            return

        df = pd.DataFrame(aggregated_list)
        df = categorize_by_volume(df, VOLUME_CATEGORIES)
        df['logoUrl'] = df['base_currency'].str.lower() + '.png'
        
        enhanced_df = await analyze_and_enhance_data(df, exchanges_map)
        
        if not enhanced_df.empty:
            save_to_database(enhanced_df)

    finally:
        logging.info("–ó–∞–∫—Ä—ã—Ç–∏–µ –≤—Å–µ—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π —Å –±–∏—Ä–∂–∞–º–∏...")
        close_tasks = [ex.close() for ex in exchanges_map.values()]
        await asyncio.gather(*close_tasks)
        logging.info("–°–∫—Ä–∏–ø—Ç —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–∏–ª —Ä–∞–±–æ—Ç—É.")


# --- –ß–ê–°–¢–¨ 5: –≠–ù–î–ü–û–ò–ù–¢–´ –°–ï–†–í–ï–†–ê ---

@app.post("/trigger")
async def trigger_run(request: Request, background_tasks: BackgroundTasks):
    auth_header = request.headers.get('Authorization')
    if not SECRET_TOKEN:
        raise HTTPException(status_code=500, detail={"error": "SECRET_TOKEN –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ."})
    
    if not auth_header or auth_header != f"Bearer {SECRET_TOKEN}":
        raise HTTPException(status_code=401, detail={"error": "–ù–µ–≤–µ—Ä–Ω—ã–π —Ç–æ–∫–µ–Ω –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏."})

    background_tasks.add_task(run_analysis_logic)
    
    return {"message": "–ó–∞–ø—Ä–æ—Å –Ω–∞ –∞–Ω–∞–ª–∏–∑ –ø—Ä–∏–Ω—è—Ç. –ü—Ä–æ—Ü–µ—Å—Å –∑–∞–ø—É—â–µ–Ω –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ."}

@app.get("/health")
async def health_check():
    """–ü—Ä–æ—Å—Ç–æ–π —ç–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏, —á—Ç–æ —Å–µ—Ä–≤–µ—Ä –∂–∏–≤ (—Ç—Ä–µ–±—É–µ—Ç—Å—è Render)."""
    return {"status": "ok"}

# --- –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è Uvicorn (–¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞) ---
if __name__ == "__main__":
    logging.info("–î–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—É: uvicorn main:app --reload")

